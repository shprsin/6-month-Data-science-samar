{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aeedd83-5d33-4cc7-a20e-be8dc49ff9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f9b6dab3-7654-445b-af38-0c5ca07298ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest regression is a supervised learning algorithm and bagging technique that uses an ensemble learning method for \n",
    "# regression in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f9e799d-3ccc-4aa1-a580-c31cd7c08f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14376d8a-9807-4e95-b95c-7c0fe16bfd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFR reduces the risk of overfitting by using an ensemble of decision tree models which works on n number of randomly selected sample data from the overall data thus reducting overfitting as models are trained on various sets of data and results are then collated using majority voting classifier to give results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79294612-b701-4904-91e4-f23d9a020615",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0f58c4dc-6250-42c9-8b53-3b9ea2eb6d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RFR uses a majority voting classifier for classification problem and average for regression problems to aggregate the presiction of multiple ddecision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "677c7d35-15ae-4f3b-a8d3-93538f2a48b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a92c9b56-7e4d-4e4d-8773-382449e67390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The parameters are :-\n",
    "# n_estimators=100, *, criterion='squared_error', max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0,\n",
    "# max_features=1.0, max_leaf_nodes=None, min_impurity_decrease=0.0, bootstrap=True, oob_score=False, n_jobs=None, random_state=None,\n",
    "# # verbose=0, warm_start=False, ccp_alpha=0.0, max_samples=None, monotonic_cst=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89e07cb8-3775-4ceb-81e6-cd0ac9f04acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "35663c2c-b22d-4da8-80ba-98c39b869c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest uses multiple decision tree models and gives an aggregated result thus reduce overfitting wheras decision is a single model on which the whole data is trained and it may lead to overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5c4f8e38-023e-4eac-84d6-baa201f5f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "142408b0-548e-4a89-8ea8-a972297d666e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest Advantages:\n",
    "#     1. Reduces Overfitting\n",
    "#     2. Can handle diverse new data better with hicher accuracy in most cases.\n",
    "#     3.it can be used in classification and regression problems.\n",
    "#     4.It solves the problem of overfitting as output is based on majority voting or averaging.\n",
    "#     5.It performs well even if the data contains null/missing values.\n",
    "    \n",
    "# Radnom Forest Diadvantages:\n",
    "#     Disadvantages:\n",
    "#     1.Random forest is highly complex compared to decision trees, where decisions can be made by following the path of the tree.\n",
    "#     2.Training time is more than other models due to its complexity.Whenever it has to make a prediction, each decision tree has to generate output for the given input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ee92231-5587-456f-8420-fa2e35d2fe1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273671ea-2780-4bdc-8d41-be15b84d4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the output of Random Forest Regressor is the average "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
