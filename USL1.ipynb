{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "565fbe9f-8f32-4725-a9cc-ab1b69abbdf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Q1 \n",
    "# Different types of Unsupervised Algorithms are :\n",
    "#     1.Kmeans: Used centroid to form clusters\n",
    "#     2.Hierarchical Clustering: Use Agglomerative/Divisive technique to form clusters\n",
    "#     3.DBScan: Uses the Pricipal of core point to form clusters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "86a511e1-39ee-4839-822f-68f7e14aab9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02f00deb-005d-4a7d-950f-b76b1894c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means Clustering is an Unsupervised Learning algorithm, which groups the unlabeled dataset into different clusters. \n",
    "# Here K defines the number of pre-defined clusters that need to be created in the process, as if K=2, there will be two clusters,\n",
    "# and for K=3, there will be three clusters and so on.\n",
    "\n",
    "# K-means triggers its process with arbitrarily chosen data points as proposed centroids of the groups and iteratively \n",
    "# recalculates new centroids in order to converge to a final clustering of the data points. Specifically, the process works\n",
    "# as follows: The algorithm randomly chooses a centroid for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55b460b5-f84d-4a43-8037-7eb770f20d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b08435c4-b22a-4ba4-bac3-2234814db58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Advantages of k-means:\n",
    "#     Relatively simple to implement.\n",
    "\n",
    "#     Scales to large data sets.\n",
    "\n",
    "#     Guarantees convergence.\n",
    "\n",
    "#     Can warm-start the positions of centroids.\n",
    "\n",
    "#     Easily adapts to new examples.\n",
    "\n",
    "#     Generalizes to clusters of different shapes and sizes, such as elliptical clusters.\n",
    "\n",
    "# Disadvantages of k-means:\n",
    "#     Choosing manually K:\n",
    "\n",
    "#     Being dependent on initial values.\n",
    "    \n",
    "#     Clustering data of varying sizes and density.\n",
    "\n",
    "#     Clustering outliers.\n",
    "\n",
    "#     Scaling with number of dimensions.\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e060b6b9-0e82-44a5-8280-93aef0ed5168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4fd8a64-4f4f-40ea-a405-67f3553cf82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can determin the K value using :\n",
    "#     Manual Iterative Process to find the WCSS value for each K and Selcting the Elbow Point.\n",
    "#     We can use KneeLocator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25684e35-2286-418f-b0bc-7b73798715d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "eadbbb5e-6c36-427d-bba3-cfa90ec48fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some of the most popular applications of clustering are recommendation engines, market segmentation, social network analysis,\n",
    "# search result grouping, medical imaging, image segmentation, and anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eef64a2e-cf53-44ea-8c9b-50d31b0e940a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1db29c90-a9ac-488a-8764-7c4e6437bb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpreting the meaning of k-means clusters boils down to characterizing the clusters.\n",
    "# A Parallel Coordinates Plot allows us to see how individual data points sit across all variables.\n",
    "# By looking at how the values for each variable compare across clusters, we can get a sense of what each cluster represents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "360bc4d9-c19d-41e3-b98c-066743cf2d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "#q7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "235a67f5-f5f5-4cb6-a208-ed4022fddec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One of the challenges of implementing K means can be choosing centroids too close to other called Random Initialization Trap. \n",
    "# We can solve this by choosing centroids with maximum distance from each other.We may use different methods such as \n",
    "# the elbow method, the silhouette method, or the gap statistic method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "527f67e5-02ad-43cd-ab83-c3f4a60c085b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
