{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "698ff2c7-d9df-4883-833b-eae22a78a0eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96db7377-0755-4df8-afa3-f25d557c09cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "# Linear regression provides a continuous output but Logistic regression provides discreet output. \n",
    "#The purpose of Linear Regression is to find the best-fitted line while Logistic regression is one step ahead and fitting the line values to the sigmoid curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e33ddf2-99ff-4798-b378-9b0126a246f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example a dataset and Probelm to Predict whther a a person is Diabetic or not we will use a Logistic Regression.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b57e8e8a-35d9-4a95-86fb-32c3b4d48ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d001511-35ca-4b71-9f7c-f8cfa7f1f91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #A linear regression line equation is written in the form of:\n",
    "\n",
    "# Y = a + bX\n",
    "\n",
    "# where X is the independent variable and plotted along the x-axis\n",
    "\n",
    "# Y is the dependent variable and plotted along the y-axis\n",
    "\n",
    "# The slope of the line is b, and a is the intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da6c4fd4-2f06-4c6a-9890-0045dd28e1cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function=(actual values-predicted values).\n",
    "# Which is also represented as\n",
    "# Cost function(d)=Y-Y’\n",
    "\n",
    "# Where Y=Actual value\n",
    "\n",
    "# Y’=Predicted value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b29223bf-a7cb-4d80-b115-c8ce3fdda16f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d071736-181e-42fd-9649-aa77cae592a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regularization helps you avoid overfitting by adding a penalty term to the cost function of your model, which measures how well your model fits the data. The penalty term reduces the complexity of your model by shrinking or eliminating some of the coefficients of your input variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1de1dad8-7e1f-4c42-95e8-9cf9a7ab156a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use L2 Regularization to Reduce Overfitting i.e adding Aplha * Slope**2 to the Cost function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec553f3c-df27-4156-b7fe-c33576838d8d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a549a836-2a14-4124-8827-13ed2c4ee61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "19d044d1-b786-4972-bf15-70d0310901ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#An ROC curve (receiver operating characteristic curve) is a graph showing the performance of a classification model at all classification thresholds. This curve plots two parameters: True Positive Rate. False Positive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b32f500d-a336-4eb8-827f-60f329423b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#5 We can use any of the Following Methods ffor Feature Selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "871c9889-85f8-45ed-a943-d7d0ed756c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Information Gain.\n",
    "# # Chi-square Test. \n",
    "# Fisher's Score\n",
    "# Mean Absolute Difference (MAD)\n",
    "# Forward Feature Selection.\n",
    "# Exhaustive Feature Selection.\n",
    "# Recursive Feature Elimination.\n",
    "# LASSO Regularization (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "821be9ae-764e-477b-bea8-0138c7e2f97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6 We can reduce imbalance Dataset by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78bfbbe9-20b5-4b00-8a7c-9d1f1f83df50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change the performance metric.\n",
    "# Change the algorithm.\n",
    "# Oversample minority class.\n",
    "# Undersample majority class.\n",
    "# # Generate synthetic samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43cafcf0-bdf7-44e2-8f9e-73d2b5d9e584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8af8669e-05ad-478f-94d2-d7c9f038ed57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dependent/response variable is binary or dichotomous. ... to help with this we can use the ,mmultiple Logistic Rgression \n",
    "# Little or no multicollinearity between the predictor/explanatory variables: If it is there we can do Feature Selection.\n",
    "# Linear relationship of independent variables to log odds. IF not we can drop the said values\n",
    "# Prefers large sample size. ... Collect Large Sample Data DO overpopulation or synthethetic Interpolation\n",
    "# Problem with extreme outliers: Removal. Scaling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e2b78c-bb2a-4c6d-9996-3eefe159d461",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
